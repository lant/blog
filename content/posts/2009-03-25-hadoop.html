---
layout: post
title: Hadoop
date: '2009-03-25T23:42:00.003Z'
author: Marc de Palol
tags:
- hadoop
modified_time: '2009-03-26T00:05:22.329Z'
blogger_id: tag:blogger.com,1999:blog-6541464271719475452.post-935755084862623929
blogger_orig_url: http://distribuint.blogspot.com/2009/03/hadoop.html
---

Els que estigueu posats en el món de l'informàtica distribuïda o bé d'alt rendiment o bé, simplement que esteu una mica a l'aguait de les novetats informàtiques potser us sonarà <a href="http://hadoop.apache.org/">Hadoop</a>.<br /><p>Hadoop és una plataforma de software que bàsicament permet escriure programes que processin unes grans quantitats de dades. Grans grans. El projecte ja té diversos anys i alguns dels seus components s'han separat en subprojectes: </p><ul><li><strong>Hadoop Core</strong>: Plataforma de Map Reduce + Sistema de fitxers distribuit.</li><li><strong>HBase</strong>: Una base de dades distribuïda i escalable.</li><li><strong>Pig</strong>: Nivell d'alt llenguatge per aplicacions que utilitzen Hadoop-core.</li><li><strong>ZooKeeper</strong>: Sistema de coordinació per Hadoop.</li><li><strong>Hive</strong>: Una espècie de SQL fer queries a les dades emmagatzemades en Hadoop (moltes dades, moltes moltes)</li></ul><p>És un projecte Open Source utilitzat en producció (molt important) en diverses empreses, tal com podeu veure <a href="http://wiki.apache.org/hadoop/PoweredBy">aquí</a>. A més, té una comunitat d'usuaris / desenvolupadors molt activa tal com podreu veure si doneu un tomb pel seu <a href="http://issues.apache.org/jira/browse/HADOOP">tracker</a></p>En aquest post parlaré exclusivament del projecte principal, Hadoop Core.<br /><p>Les característiques que ells destaquen en la seva pàgina són les següents: </p><ul><li><b>Escalabilitat:</b> Pot manejar grans quantitats de dades (petabytes) i té escalabilitat horitzontal, és a dir, si necessites més potència o més espai, simplement afegeixes màquines. </li><li><b>Econòmic: </b>És Open Source (llicència Apache) i treballa amb qualsevol tipus de màquines, no és necessari que siguin servidors d'alta gamma. A més, és una plataforma de software que suposa que els errors de hardware són usuals i per tant, sap reaccionar. També cal destacar que està preparat per còrrer al <a href="http://aws.amazon.com/ec2/">Amazon EC2</a></li><li><b>Segur: </b>Sempre es mantenen diverses còpies de les dades repartides en diverses màquines, així ens estalviem desgràcies quan una màquina decideix morir sense avisar. </li></ul><p>Hadoop és capaç de processar grans quantitats de dades perquè utilitza Map Reduce. Map Reduce és un model de programació pensat, o més bé, readaptat, per procés de moltes dades. Amb això voldria aclarar que de fet, només serveix per això. Sembla ser que hi ha certa moda en utilitzar Map Reduce en alguna de les seves implementacions per moltes coses. Si no es té una entrada de com a mínim gigues de dades probablement no sigui el que es necessita.  </p><p>Bé, els causants de tota aquesta febre MR (Map Reduce) van ser Google quan van publicar un <a href="http://labs.google.com/papers/mapreduce.html">article</a> on explicaven què era, com es programava i com ho utilitzaven en producció a diari en els seus clústers. A partir d'aquí van començar a aparèixer implementacions d'aquest model de programació en diversos llenguatges, una de les més importants, si no és la que més és sens dubte Hadoop. </p><p>En resum, MR i per tant Hadoop treballen de la següent manera (molt per sobre):</p><p>Tenim les dades al sistema de fitxers distribuit que comparteixen totes les màquines que conformen el nostre clúster. Tenim un programa que implementa MR mitjançant Hadoop, això bàsicament vol dir que hem programat un programa semblant a <a href="http://hadoop.apache.org/core/docs/current/mapred_tutorial.html#Example%3A+WordCount+v1.0">aquest</a>a, el qual té una classe <code>Mapper</code>, amb un mètode <code>map</code> i una classe <code>Reducer</code> amb un mètode <code>reduce</code>. </p><p>Hadoop parteix el clúster en <i>mappers</i> i <i>reducers</i>, una màquina pot ser mapper i reducer a l'hora, això es pot definir en la configuració del sistema. Les màquines que fan de mappers agafen les dades del sistema de fitxers distribuit i li apliquen la funció map. Així de bon principi ja tenim tot de màquines que estan llegint les dades d'entrada de forma paral·lela. <br /><br />MR té uns requeriments per les dades. Bàsicament han d'esser de la forma. Clau -> Valor, on la clau i el valor poden ser qualsevol cosa. Per tant, un cas típic seria un log d'apache:<br /><pre><br />127.0.0.1 - - [31/Jul/2008:00:37:04 +0100] "GET /~marc/images/imatge1.jpg HTTP/1.1" 200 16624<br />127.0.0.2 - - [31/Jul/2008:00:37:05 +0100] "GET /~marc/images/imatge2.jpg HTTP/1.1" 200 16624<br />127.0.0.3 - - [31/Jul/2008:00:37:06 +0100] "GET /~marc/images/imatge3.jpg HTTP/1.1" 200 16624<br />127.0.0.1 - - [31/Jul/2008:00:37:04 +0100] "GET /~marc/images/imatge3.jpg HTTP/1.1" 200 16624<br /></pre>Per exemple en aquest programa ens interessa saber quines IPs han agafat quines imatges. Per tant podriem dir-li al mapper que la clau de sortida sigui la imatge, i que el valor de la clau sigui la IP: <br /><pre><br />Clau   Valor<br />imatge1.jpg  127.0.0.1 <br />imatge2.jpg 127.0.0.2 <br />imatge3.jpg 127.0.0.3 <br />imatge3.jpg 127.0.0.1<br /></pre>Ok, per cada Clau/Valor que el mapa troba l'envia a un <em>reducer</em>. És important notar que no associa res de res, en aquest cas enviarà una clau/valor per cada linia de fitxer. Aquesta és una part molt interessant ja que el mètode <em>map</em> simplement invoca una funció amb la clau i el valor com a paràmetres i se n'oblida. Aquests valors són emmagatzemats "màgicament" al sistema de fitxers distribuit de forma totalment transparent fins que tots els <em>mappers</em> han acabat. Això vol dir que els <em>reducers</em> no comencen a processar les dades fins que els <em>mappers</em> estiguin (en veritat si que comencen en certa manera, però no és important ara). Hadoop té un particionador de manera que, atenció que això és important, cada <em>reducer</em> (cada instància d'un <em>reducer</em>) rep una i només una clau amb una llista dels valors: Això és una mica espinós per entendre, exemple:<br /><pre><br />Clau 1 / Valor A<br /> Clau 2 / Valor B<br /> Clau 3 / Valor A<br /> Clau 2 / Valor A<br /> Clau 3 / Valor C<br /></pre>I el reducer rebrà:<br /><pre><br />Reducer1 : Clau 1 amb una llista que contindrà: Valor A<br />Reducer2 : Clau 2 amb una llista que contindrà: Valor B, Valor A<br />Reducer3 : Clau 3 amb una llista que contindrà: Valor A, Valor C <br /></pre>Per tant hi haurà tants reducers com claus tingui la sortida el mapper. En l'exemple anterior es tradueix a: <br /><pre><br />imatge1.jpg 127.0.0.1<br />imatge2.jpg 127.0.0.2<br />imatge3.jpg 127.0.0.3, 127.0.0.1<br /></pre>Llavors lògicament el reducer pot fer el que vulgui amb aquestes dades. L'exemple aquest és extremadament senzill, però pensem que un map i un reduce complex poden fer les mil i una bestieses i si estem parlant d'un fitxer de log complert d'apache d'alguna pàgina important pot ser molt i molt gros.<br /><p></p><p>Un cop el reduce està també escriu els resultats en forma clau valor. Aquests resultats són guardats al sistema de fitxers distribuit. <br /></p>Podeu trobar molta més informació sobre Map/Reduce + Hadoop al <a href="http://hadoop.apache.org/core/docs/current/mapred_tutorial.html">tutorial</a> de hadoop. <br /><p>Bé, en pròxims articles entraré més en detalls sobre Hadoop i probablement publicaré snippets de codi, amb problemes que em vaig trobant al dia a dia i alguns números.<br /></p>